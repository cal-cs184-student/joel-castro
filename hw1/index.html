<html>
	<head>
		<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=default'></script>
		<link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600&display=swap" rel="stylesheet">
		<style>
			h1 {
				text-align: center;
			}

			.container {
				margin: 0 auto;
				padding: 60px 20%;
			}

			figure {
				text-align: center;
			}

			img {
				display: inline-block;
			}

			body {
				font-family: 'Inter', sans-serif;
			}
		</style>
	</head>
	<body>
		<div class="container">
			<h1>CS184/284A Spring 2025 HW 1: Rasterizer - Write-Up</h1>
			<div style="text-align: center;">By Joel Castro </div>

			<br>

			Link to webpage: <a href="https://cal-cs184-student.github.io/joel-castro/">cal-cs184-student.github.io/joel-castro/</a>

			<br>

			Link to GitHub repository: <a href="https://github.com/cal-cs184-student/sp25-hw1-plz/tree/master">github.com/cal-cs184-student/sp25-hw1-plz</a>

			<figure>
				<img src="https://raw.githubusercontent.com/cal-cs184-student/joel-castro/refs/heads/master/hw1/lion.jpg" alt="Lion" style="width:50%" />
				<figcaption>Rasterizer</figcaption>
			</figure>

			<!--
	We've already added one heading per task, to make your write-up as navigable when grading. Please fit your write-up within these sections!
	-->

			<h2>Overview</h2>
			<p>
				This is my implementation of a C++ rasterizer. I have always wondered how data can be transformed into something that can be shared across our digital devices;
				this project dove into the weeds of how we represent images in memory and the algorithms pictures have to undergo to decide what is drawn at any particular pixel to
				give a good representation of it. The most insightful takeaway from this experience was beginning to think of images as signals-- like any other signal being sampled,
				(in our case, from mathematically defined, continuous shapes --> to pixels on a screen) images are subject to the effects of aliasing and other visual imperfections. Fortunately,
				we'll talk about ways to mitigate these effects!
			</p>

			<h2>Task 1: Drawing Single-Color Triangles</h2>
			<p>
				In this task, we tackle the problem of drawing and filling triangles on a screen. To accomplish this we must answer questions like: how do we know when a pixel is inside a triangle? What does it mean
				for a triangle to be colored? How can we take data and turn it into output for our RGB displays?
			</p>

			<h3> How Triangles are rasterized</h3>
			<p>
				My unoptimized attempt consists of iterating through every pixel in the specified triangle's
				bounding box (defined by min/max coordinates along either either x-y axis). For every pixel in question,
				its center point (that is, (int)x/y coordinate +0.5) was put through the line test described in lecture.
				Since the line test returns a negative value if a point is to the left of it and a non-negative value otherwise, this could be
				used to determine whether a given point was within a triangle (i.e. to the same side of all 3 lines/sides of a triangle). To account
				for triangles having different winding order, I defined two conditions that could trigger a pixel fill: a point is the **left** of
				3 sides, **OR** a point is to the **right** of all 3 sides.
			</p>
			<p>
				This is no worse than simply checking each sample within the bounding box of the triangle, but it literally is doing just that
				(and I went on to add some optimization as I'll talk about below).
			</p>

			<figure>
				<img src="https://raw.githubusercontent.com/cal-cs184-student/joel-castro/refs/heads/master/hw1/basicSVG4.png" alt="Screenshot of working SVG4" style="width:50%" />
				<figcaption>Screenshot of working SVG4</figcaption>
			</figure>

			<h3>Opitmizations</h3>
			<p>
				In order to improve the performance of my algorithm, I precomputed line-test coefficients outside of loops. For instance,
				any differences between points were computed prior to the nested for-loop over pixels. Also, terms in line tests that relied on
				on the y-value of the pixel in question were computed outside of the inner-most for-loop as the same value is used along
				an entire row of pixels. Moreover, in order to take full advantage of caching from memory accesses from calls to fill_pixels,
				I accessed the frame buffer in row-major order (i.e. I traversed along all x-coordinates in a row before moving on the the next
				y-cordinate). Lastly, I made use of C++ built-in parallelization capabilities by using ``#pragma omp parallel for collapse(2)`` to
				split up iterations of the nested for-loop across threads.
			</p>
			<p>
				There was also an attempt at SIMD parallelization as well, but I ran into
				precision problems (a few triangles missing here and there) that weren't worth debugging because, even at that stage, test svgs
				rendered slower with SIMD than without it. Perhaps the overhead of loading numbers into vectors outweighed SIMD parallelization
				for the simple examples we are testing on(?).
			</p>

			<p>These were my timing results per svg:</p>
			<ul>
				<li>
					<strong>Basic Implementation Time Trial</strong>:
					<ul>
						<li>#3: 0.024 seconds</li>
						<li>#4: 0.001 seconds</li>
						<li>#5: 0.002 seconds</li>
						<li>#6: 0.003 seconds</li>
					</ul>
				</li>
				<li>
					<strong>W/ Optimization</strong>:
					<ul>
						<li>#3: 0.012 seconds</li>
						<li>#4: 0.001 seconds</li>
						<li>#5: 0.002 seconds</li>
						<li>#6: 0.002 seconds</li>
					</ul>
				</li>
			</ul>

			<p>and the corresponding implementations time trail:</p>

			basic implementation:
			<pre><code>
				float min_x = std::min({x0, x1, x2});
				float min_y = std::min({ y0, y1, y2 });
				float max_x = std::max({ x0, x1, x2 });
				float max_y = std::max({ y0, y1, y2 });
				for (int x = min_x + 0.5; x < max_x; x++) { //for every (center of +0.5) pixel in a row of pixels
					for (int y = min_y + 0.5; y < max_y; y++) { //for every row in the display
						float line_test1 = (x - x0) * (y1 - y0) - (y - y0) * (x1 - x0);
						float line_test2 = (x - x1) * (y2 - y1) - (y - y1) * (x2 - x1);
						float line_test3 = (x - x2) * (y0 - y2) - (y - y2) * (x0 - x2);

						if ((line_test1 > 0 && //check if to left of all 3 lines (i.e in triangle)
						line_test2 > 0 &&
						line_test3 > 0) ||
						(line_test1 < 0 && //check if to right of all 3 lines (i.e in triangle)
						line_test2 < 0 &&
						line_test3 < 0)) {
							int sx = (int)floor(x);
							int sy = (int)floor(y);
							fill_pixel(sx, sy, color);
						}
					}
				}
			</code></pre>

			<p>and w/optmizations:</p>
			<pre><code>
				float min_x = std::min({ x0, x1, x2 });
				float min_y = std::min({ y0, y1, y2 });
				float max_x = std::max({ x0, x1, x2 });
				float max_y = std::max({ y0, y1, y2 });

				float Y0 = y1 - y0;
				float Y1 = y2 - y1;
				float Y2 = y0 - y2;

				float X0 = x1 - x0;
				float X1 = x2 - x1;
				float X2 = x0 - x2;

				#pragma omp parallel for collapse(2)
				for (int j = min_y; j <= max_y; j++) { //for every (center of +0.5) pixel in a row of
					float y = j + 0.5;
					float line_test1Y = -(y - y0) * X0;
					float line_test2Y = -(y - y1) * X1;
					float line_test3Y = -(y - y2) * X2;
					int sy = (int)floor(y);
					for (int i = min_x; i <= max_x; i++) { //for every row in the
						float x = i + 0.5;
						float line_test1 = line_test1Y + (x - x0) * Y0;
						float line_test2 = line_test2Y + (x - x1) * Y1;
						float line_test3 = line_test3Y + (x - x2) * Y2;

						if ((line_test1 >= 0 && //check if to left of all 3 lines (i.e in triangle)
						line_test2 >= 0 &&
						line_test3 >= 0) ||
						(line_test1 < 0 && //check if to right of all 3 lines (i.e in triangle)
						line_test2 < 0 &&
						line_test3 < 0)) {
						int sx = (int)floor(x);
						fill_pixel(sx, sy, color);
						}
					}
				}
			</code></pre>

			<!--
	<p>Here is an example 2x2 gridlike structure using an HTML table. Each <b>tr</b> is a row and each <b>td</b> is a column in that row. You might find this useful for framing and showing your result images in an organized fashion.</p>
	<div style="display: flex; flex-direction: column; align-items: center;">
		<table style="width: 100%; text-align: center; border-collapse: collapse;">
		  <tr>
			<td style="text-align: center;">
			  <img src="images/image1.png" width="400px"/>
			  <figcaption>Caption goes here.</figcaption>
			</td>
			<td style="text-align: center;">
			  <img src="images/image2.png" width="400px"/>
			  <figcaption>Caption goes here.</figcaption>
			</td>
		  </tr>
		  <tr>
			<td style="text-align: center;">
			  <img src="images/image3.png" width="400px"/>
			  <figcaption>Caption goes here.</figcaption>
			</td>
			<td style="text-align: center;">
			  <img src="images/image4.png" width="400px"/>
			  <figcaption>Caption goes here.</figcaption>
			</td>
		  </tr>
		</table>
	</div>
	-->

			<h2>Task 2: Antialiasing by Supersampling</h2>
			How to get rid of "jaggies"?

			<h3>Implementing Supersampling</h3>
			<p>
				The triangle supersampling algorithm I implemented works as an extension to my rasterizer from task 1.
				For every pixel to be rasterized, I save `sqrt(sample_rate)*sqrt(sample_rate)` color samples to the sample_buffer for a total of `width*height*sample_rate` color samples.
				Samples corresponding to the same pixel were saved next to each other in the sample_buffer for convenient indexing.
				To resolve to the frame_buffer, the `sample_rate` color samples corresponding to a pixel are averaged to produce the color that is actually outputted at said pixel.
				This implementation required the dynamic resizing of the sample_buffer. Previously it was set to a length of `height*width`, but in order to make enough room for extra
				samples, the sample_buffer is resized to a length of `width*height*sample_rate` whenever the sample_rate is changed or the render window is resized. Moreover, the fill_pixel
				method used to rasterize points and lines needed to be modified to account for the fact that, a single pixel no longer corresponds to just a single color in the sample_buffer.
				For a sample_buffer slot that was to be filled with `color`, instead a `sample_buffer` amount of memory in the sample_buffer is to be filled with that same `color`.
			</p>
			<p>
				Supersampling is useful for minimizing "jaggies" (i.e. noticeable pixelation)
				because they create the illusion of smoothness through the gradual drop of intensity of color of rasterized pixels.
				Jaggies are an artifact of a phenomenon known as aliasing, which is (in a nutshell) the loss of information due to undersampling. In our case, the (discrete and limited) number of pixels
				on our displays undersample the changes in the color of underlying (continuous/infinite-resolution) SVGs causing us to misrepresent shapes.
				By supersampling (increasing the sample rate per pixel), instead of having each pixel be strictly one color or another, we can set pixels to be an intermediate intensity color so that it conveys being partially both (i.e at the edge of a shape).
				This creates color transitions that emulate the smoothness of the underlying shape being rasterized. This intermediate value is computed by making the intensity of the pixel in question proportional to how many of the
				samples within said pixel contribute to the shape being drawn. This processing of alleviating symptoms of aliasing due to undersampling when
				discretizing a continuous signal (in our case, continuous SVG vectors -> discrete pixels) is know as antialiasing and it helps our images appear higher resolution!
			</p>

			<div style="display: flex; flex-direction: column; align-items: center;">
				<table style="width: 100%; text-align: center; border-collapse: collapse;">
					<tr>
						<td style="text-align: center;">
							<img src="https://raw.githubusercontent.com/cal-cs184-student/joel-castro/refs/heads/master/hw1/svg4_sample_rate_1.png" width="400px" />
							<figcaption>supersampled SVG4 SR=1.</figcaption>
						</td>
						<td style="text-align: center;">
							<img src="https://raw.githubusercontent.com/cal-cs184-student/joel-castro/refs/heads/master/hw1/svg4_sample_rate_4.png" width="400px" />
							<figcaption>supersampled SVG4 SR=4.</figcaption>
						</td>
					</tr>
					<tr>
						<td style="text-align: center;">
							<img src="https://raw.githubusercontent.com/cal-cs184-student/joel-castro/refs/heads/master/hw1/svg4_sample_rate_9.png" width="400px" />
							<figcaption>supersampled SVG4 SR=9.</figcaption>
						</td>
						<td style="text-align: center;">
							<img src="https://raw.githubusercontent.com/cal-cs184-student/joel-castro/refs/heads/master/hw1/svg4_sample_rate_16.png" width="400px" />
							<figcaption>supersampled SVG4 SR=16.</figcaption>
						</td>
					</tr>
				</table>
			</div>

			<h3>Extra Credit - Other anti-aliasing methods: Random Sampling</h3>
			Wikipedia lists a bunch of other common sampling patterns: <a href="https://en.wikipedia.org/wiki/Supersampling">en.wikipedia.org/wiki/Supersampling</a>. I chose to implement random sampling because I thought it'd look funny... I was correct:
			<figure>
				<img src="https://raw.githubusercontent.com/cal-cs184-student/joel-castro/refs/heads/master/hw1/random_sampling_eg.png" alt="random sampling example" style="width:50%" />
				<figcaption>Look how fluffy and cute these once sharp and scary shapes have become 😁.</figcaption>
			</figure>
			<p>Here is the same example at different sampling rates. Notice how even at the same sampling rate as the above example, no two renders are exactly the same!</p>

			<p>This was implemented by simply computing a random position within every pixel to take each sample from like so:</p>
			<pre><code>
				*/In pseudocode/*
				for (i in bounding_box.width) {
					for (j in bounding_box.height) {
						double x = i + (double)std::rand() / RAND_MAX; //(i.e. add a number between 0 and 1)
	                			double y = j + (double)std::rand() / RAND_MAX;
						...
						//sampling at (x, y)
					}
				}
			</code></pre>
							
			<div style="display: flex; flex-direction: column; align-items: center;">
				<table style="width: 100%; text-align: center; border-collapse: collapse;">
					<tr>
						<td style="text-align: center;">
							<img src="https://raw.githubusercontent.com/cal-cs184-student/joel-castro/refs/heads/master/hw1/random_sampling_1.png" width="400px" />
							<figcaption>random supersampled SVG4 SR=1.</figcaption>
						</td>
						<td style="text-align: center;">
							<img src="https://raw.githubusercontent.com/cal-cs184-student/joel-castro/refs/heads/master/hw1/random_sampling_2.png" width="400px" />
							<figcaption>random supersampled SVG4 SR=4.</figcaption>
						</td>
					</tr>
					<tr>
						<td style="text-align: center;">
							<img src="https://raw.githubusercontent.com/cal-cs184-student/joel-castro/refs/heads/master/hw1/random_sampling_3.png" width="400px" />
							<figcaption>random supersampled SVG4 SR=9.</figcaption>
						</td>
						<td style="text-align: center;">
							<img src="https://raw.githubusercontent.com/cal-cs184-student/joel-castro/refs/heads/master/hw1/random_sampling_4.png" width="400px" />
							<figcaption>random supersampled SVG4 SR=16.</figcaption>
						</td>
					</tr>
				</table>
			</div>
			<p>
				Interestingly, the shapes begin to look sharp again once we increase the sampling rate. On one hand, the randomness could make for a cool stylistic effect, on another, 
				shapes appear just as jagged as normal sampling within the same amount of sample increases.
			</p>
				
			<h2>Task 3: Transforms</h2>
			Next, I implemented 3 transforms based on: <a href="https://developer.mozilla.org/en-US/docs/Web/SVG/Attribute/transform">https://developer.mozilla.org/en-US/docs/Web/SVG/Attribute/transform</a>.

			<h3> Creating an updated version of cubeman doing something more interesting (using svg transformation operations)</h3>

			<figure>
				<img src="https://raw.githubusercontent.com/cal-cs184-student/joel-castro/refs/heads/master/hw1/block_man.png" alt="transformed cubeman" style="width:50%" />
				<figcaption>Dapper cubeman.</figcaption>
			</figure>

			Look, he's waving hello! He's wearing a shirt, a hat, and jeans-- I wonder what he's dressed up for....

			<h2>Task 4: Barycentric coordinates</h2>
			<p>
				Barycentric coordinates (α,β,γ) are a method for describing the "pull" that each vertex of a triangle has on the position
				of a point.  Any point on a plane (x,y) can be written as the weighted (by the barycentric coordinates) sum of the vertex coordinates: (x, y) = α*A + β*B + γ*C,
				where (α,β,γ) are proportions (i.e. between 0 and 1) for how close a given point is to (A, B, C) respectively. It follows
				then that for any point within the triangle written in barycentric coordinates, it must be that α + β + γ = 1. To build some intuition, we can think of (α,β,γ) as percentages where 1 (100%) represents that the corresponding vertex has all the pull
				and 0 (0%) means it has none. Would it make sense for more than one point to be able to have 100% of the pull?
			</p>

			<p>To visualize this, let (α,β,γ) = (r, g, b), representing proportions for how much red, blue, or green a pixel sampling at the corresponding (x,y) is.</p>
			<figure>
				<img src="https://raw.githubusercontent.com/cal-cs184-student/joel-castro/refs/heads/master/hw1/barycentric_triangle.png" alt="barycentric triangle filled with interpolated rgb values" style="width:50%" />
				<figcaption>Barycentric triangle.</figcaption>
			</figure>

			<p>
				You can see how at, for example, (1,0,0), A has 100% of the pull so it is most red there (since α=r). Analogous statements can be made for B (and it's relationship to β=g) to explain why this is the most green point, as well as to explain why C (γ = b) is the most blue.
				The gradient of color filling the triangle visualizes the pull that A, B, and C have at any point (x,y) in the triangle.
			</p>

			<h2>Task 5: "Pixel sampling" for texture mapping</h2>
			What if I want to fill triangles with something more interesting than perfect RGB colors? Can I fill triangles with... pictures?

			<h3>What is pixel sampling?</h3>
			When we want a shape we draw onto the screen to take on a particular color scheme, or "texture", we can draw that texture onto our shape by asking ourselves the question: at every pixel position in my shape, what is the corresponding color of my texture?
			In other words, we *sample* the texture that we want to apply to our shape to figure out how to draw it onto the shape we want to render.

			<h3>Implementation</h3>
			<p>
				But how does one determine what the corresponding coordinates between a shape and a texture? This is where uv-mapping comes into play. If you've ever taken a multivariable calculus class you might have heard of this as a math concept. Essentially, we want to
				take the coordinates from one space and transform them into the same coordinates only written in another space (of a different basis). In our case, the two spaces can be thought of as a triangle in our shape and a corresponding triangle in our texture. So we want to have
				coordinates relative to a point's position in triangles... do we have a tool for that? That's right, Baycentric coordinates from Task 4!
			</p>
			<p>
				And with this realization, my `rasterize_textured_triangle` algorithm works nearly identically to the interpolation from before, the major change being that instead of using the barycentric coordinates as weights for RGB value at a pixel, they are used as weights for
				picking (u, v) coordinates on the texture.
			</p>

			<p>
				There is one more issue with this that we need to address. When we try to sample an (x, y) shape point from the (u, v) texture space, how can we be sure that there is always a 1-to-1 correct sample to pick? Well, the answer is we can't :(. Fortunately, we can get pretty
				close; for this project, I have implemented two solutions to this problem: nearest sampling and bilinear sampling.
			</p>

			<p>
				Nearest Sampling works by simply picking the single sample point nearest to where (u,v) mapped to. This can often leads to more obvious pixelation when the texture is not high resolution enough.
				On the other hands, Bilinear Sampling works by picking the 4 texture sample points nearest to (u,v) (i.e. a 2x2 block roughly centered around (u, v)). Then a linear interpolation of the sampled (RGB) values is performed (first horizontally and then vertically) to produce the final
				value mapped to (x,y).
			</p>

			<h3>Result Examples: Nearest Sampling v.s. Bilinear Sampling (1 and 16 sample rates)</h3>
			<div style="display: flex; flex-direction: column; align-items: center;">
				<table style="width: 100%; text-align: center; border-collapse: collapse;">
					<tr>
						<td style="text-align: center;">
							<img src="https://raw.githubusercontent.com/cal-cs184-student/joel-castro/refs/heads/master/hw1/linear_sampling1.png" width="400px" />
							<figcaption>nearest sampling w/sample rate=1.</figcaption>
						</td>
						<td style="text-align: center;">
							<img src="https://raw.githubusercontent.com/cal-cs184-student/joel-castro/refs/heads/master/hw1/bilinear_sampling1.png" width="400px" />
							<figcaption>bilinear sampling w/sample rate=1.</figcaption>
						</td>
					</tr>
					<tr>
						<td style="text-align: center;">
							<img src="https://raw.githubusercontent.com/cal-cs184-student/joel-castro/refs/heads/master/hw1/linear_sampling16.png" width="400px" />
							<figcaption>nearest sampling w/sample rate=16.</figcaption>
						</td>
						<td style="text-align: center;">
							<img src="https://raw.githubusercontent.com/cal-cs184-student/joel-castro/refs/heads/master/hw1/bilinear_sampling16.png" width="400px" />
							<figcaption>bilinear sampling w/sample rate=16.</figcaption>
						</td>
					</tr>
				</table>
			</div>

			<p>
				You will notice that the effects of Bilinear Sampling are most noticeable at `sample_rate=1`. The effects of Bilinear Sampling become more subtle at `sample_rate=16`. This is because the higher sample rate has already done away with a majority of the jaggies that
				Bilinear Sampling also helps do away with this. However, comparing particular details at a time, it is clear that Bilinear Sampling adds continuity here as well.
			</p>

			<h2>Task 6: "Level Sampling" with mipmaps for texture mapping</h2>
			Taking it to the next level.

			<h3>What is level sampling?</h3>
			Level sampling is a technique for sampling for texture mapping that involves, picking which resolution of the texture to sample from. For this, we work with a pre-computed bitmap, or an object containing the texture at various levels of resolution (decreasing in resolution by a factor of 2 at each level).
			Informally speaking, we choose which level of the mipmap to sample from based on how much it is stretched out from sample space to screen space. Picking an appropriate level helps alleviate the blurring and aliasing effects of sampling a near object with too low a resolution, or a faraway object with too low resolution.

			<h3>Implementation</h3>
			My implementation of level sampling built upon the rasterization scheme I used in task 5 for pixel sampling. The changes from the rasterization algorithm since then include using barycentric coordinates to not only calculate the (u,v) texture coordinates of every pixel (x,y), but also
			the pixel texture coordinates of (u_dx, v_dx) corresponding to (x+1, y), and (u_dy, v_dy) corresponding to (x, y+1). These allow us to determine the "stretching" factor discussed earlier that will help with computing a sensible mipmap level. More formally, the mipmap level (D) we sample
			a texture from at a given point is given by:
			<figure>
				<img src="https://raw.githubusercontent.com/cal-cs184-student/joel-castro/refs/heads/master/hw1/level_formula.png" alt="bitmap level formula" style="width:50%" />
				<figcaption>bitmap level formula.</figcaption>
			</figure>

			<p>
				But wait, isn't this function continuous? What if we compute some level that looks like D = 2.44432? Do we have a sampling level of 2.44432 precomputed in our mipmap? Once more, the answer is an unfortunate no :(. However, this is where the following three selection schemes come into play:
				Level = Zero, Level = Nearest, and Level_Bilinear.
			</p>
			<p>
				In task 5, I hardcoded sampling to always occur at bitmap level 0 (full resolution). This is all Level = Zero, or L_Zero entails.
			</p>

			<p><em>Level = Nearest</em> builds on the computation of D. Because bitmap levels are limited to integers greater than or equal to 0, this scheme works by simply rounding D (`round(D)`) to find the closest existing level to the one computed.</p>

			Finally, </em>Level_Bilinear</em> samples from both level `floor(D)` and level `ceil(D)` (below and above the computed level) and interpolates between the RGB values found at either sample.

			<h3>Pixel Sampling v.s. Level Sampling v.s. Sample Rate</h3>
			<p>
				Your choice of pixel/level sampling techniques and sampling rate have tradeoffs between speed, memory usage, and antialiasing power. In general nearest pixel sampling is more costly than bilinear pixel sampling simply because of the extra computation of interpolating values between
				samples. The same can be said about level nereast and bilinear sampling. However, sampling a texture from relatively distant sample points or suddenly switching mipmap levels can cause distortion (e.g. jaggies). In both cases, using bilinear sampling over nearest sampling will antialias
				those sudden changes, so perhaps the computational cost can be justified.
			</p>

			<p>
				Similar to the relationship between nearest and linear sampling, altering the sample rate from low to high helps antialias images but it comes at the cost of additional computation (more sample points to check against triangles), but also memory. The higher the sampling rate, the
				more memory must be allocated to the sample buffer to hold more samples!
			</p>

			<div style="display: flex; flex-direction: column; align-items: center;">
				<table style="width: 100%; text-align: center; border-collapse: collapse;">
					<tr>
						<td style="text-align: center;">
							<img src="https://raw.githubusercontent.com/cal-cs184-student/joel-castro/refs/heads/master/hw1/L_Zero_AND_P_Nearest.png" width="400px" />
							<figcaption>L_Zero + P_Nearest.</figcaption>
						</td>
						<td style="text-align: center;">
							<img src="https://raw.githubusercontent.com/cal-cs184-student/joel-castro/refs/heads/master/hw1/L_Zero_AND_P_Linear.png" width="400px" />
							<figcaption>L_Zero + P_Linear.</figcaption>
						</td>
					</tr>
					<tr>
						<td style="text-align: center;">
							<img src="https://raw.githubusercontent.com/cal-cs184-student/joel-castro/refs/heads/master/hw1/L_Nearest_AND_P_Nearest.png" width="400px" />
							<figcaption>L_Nearest + P_Nearest.</figcaption>
						</td>
						<td style="text-align: center;">
							<img src="https://raw.githubusercontent.com/cal-cs184-student/joel-castro/refs/heads/master/hw1/L_Nearest_AND_P_Linear.png" width="400px" />
							<figcaption>L_Nearest + P_Linear.</figcaption>
						</td>
					</tr>
				</table>
			</div>

			<p>Notice the different sampling effects through the pixel inspector. Using our most basic techniques, you'll notice we achieve our highest frequency output (i.e. most pixelated) images. This is in contrast to using linear sampling and/or level sampling.</p>


			<h2>Task 7: Draw Something Creative!</h2>
			Not done in time for hw deadline, but I plan to submit :).
	</body>
</html>
